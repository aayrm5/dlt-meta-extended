{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5073e9be-2b03-4003-b512-cf2ba1cfb9e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Notebook to trigger the workflow containing 2 dlt pipelines `hkjc_mv_customer_segment_gold` and `hkjc-wagering-dashboard-bronze-silver-gold-dlt-pipeline`.\n",
    "#### Trigger: To be triggered at 6 AM if it's a race day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22704bd5-36b9-43a6-b6a7-b1ecc7001c12",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks.sdk.service.pipelines import PipelineState\n",
    "from databricks.sdk.service.jobs import RunLifeCycleState\n",
    "import time\n",
    "import logging\n",
    "import pyspark.sql.functions as F\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c37131d-e065-4a91-ad00-457fb674a64a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "bearer_token = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiToken().getOrElse(None)\n",
    "workspace_url = spark.conf.get('spark.databricks.workspaceUrl')\n",
    "\n",
    "sdk_workspace_client = WorkspaceClient(token = bearer_token, host = workspace_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "601d093f-9994-42f0-b7ab-053e75f6ac54",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "wf_job_name = dbutils.widgets.get(\"wf_job_name\")\n",
    "race_day_details_table = dbutils.widgets.get(\"race_day_details_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ecc9e69-55ea-441b-a4db-330f68007a7f",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Find job by it's name"
    }
   },
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'Authorization': f'Bearer {bearer_token}',\n",
    "    'Content-Type': 'application/json'\n",
    "}\n",
    "url = f\"https://{workspace_url}/api/2.1/jobs/list\"\n",
    "params = {'name': wf_job_name}\n",
    "\n",
    "response = requests.get(url, headers=headers, params=params)\n",
    "\n",
    "try:\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if data.get('jobs'):\n",
    "            job = data['jobs'][0]\n",
    "            wf_job_id = job['job_id']\n",
    "            print(f\"Found Workflow '{wf_job_name}' -> Job ID: {wf_job_id}\")\n",
    "        else:\n",
    "            print(f\"Error: Workflow '{wf_job_name}' not found.\")\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code} - {response.text}\")\n",
    "except Exception as e:\n",
    "        print(f\"Error finding Workflow '{wf_job_name}'\")\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cdb5b665-087d-480f-a585-648bc2ef0baf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_dlt_pipeline_ids(client, workflow_job_id):\n",
    "    \"\"\"Function to get DLT pipeline IDs from workflow\"\"\"\n",
    "    pipeline_ids=[]\n",
    "    # Get job details and extract DLT pipeline IDs\n",
    "    job = client.jobs.get(job_id=workflow_job_id)\n",
    "    \n",
    "    if job.settings and job.settings.tasks:\n",
    "        for task in job.settings.tasks:\n",
    "            if hasattr(task, 'pipeline_task') and task.pipeline_task:\n",
    "                pipeline_ids.append(task.pipeline_task.pipeline_id)\n",
    "                print(f\"Found DLT task '{task.task_key}' -> Pipeline ID: {task.pipeline_task.pipeline_id}\")\n",
    "    \n",
    "    return pipeline_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8019852-cb90-4026-8d98-3987e9e67c29",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pipeline_ids = get_dlt_pipeline_ids(sdk_workspace_client, wf_job_id)\n",
    "print(pipeline_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6bd14813-4c9a-4a32-bf96-735a8addf016",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Need to check the race-day "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2902cc5e-aece-494e-8317-83b67e7213cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "race_table = spark.read.table(race_day_details_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0e9524d-d752-4e47-a312-b03f2e1245f5",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Check if it's a race day"
    }
   },
   "outputs": [],
   "source": [
    "race_day_record = race_table.filter(\"is_current = 1 and date(meeting_date) = current_date() and meeting_location in ('HV', 'ST')\") \\\n",
    "           .groupBy(\"meeting_location\") \\\n",
    "           .agg(F.count(\"*\").alias(\"race_day_count\")).collect()\n",
    "\n",
    "if race_day_record:\n",
    "    is_race_day = True if race_day_record[0]['race_day_count'] > 0 else False\n",
    "    print(is_race_day)\n",
    "else:\n",
    "    print(\"Race day record not found\")\n",
    "    is_race_day = False\n",
    "    print(is_race_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8f32d2cb-4140-4a7d-a69f-aa9af5e15ac8",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Race Day"
    }
   },
   "outputs": [],
   "source": [
    "if is_race_day:\n",
    "    #check if the DLT pipelines are running, if yes stop them before trigger the workflow job\n",
    "    for pl_id in pipeline_ids:\n",
    "        pipeline_details = sdk_workspace_client.pipelines.get(pipeline_id = pl_id)\n",
    "        if pipeline_details.state == PipelineState.RUNNING:\n",
    "            # Stop the pipeline\n",
    "            sdk_workspace_client.pipelines.stop(pipeline_id=pl_id)\n",
    "            print(f\"Stop request submitted to the pipeline: {pipeline_details.name}\")\n",
    "            \n",
    "\n",
    "    #Run the Wagering dashboard workflow\n",
    "    time.sleep(60) # wait a min for the pipelines to stop before triggering the job\n",
    "    run = sdk_workspace_client.jobs.run_now(job_id=wf_job_id)\n",
    "    print(f\"check the job-run triggered over here --> https://{workspace_url}/jobs/{wf_job_id}/runs/{run.run_id}\")\n",
    "else:\n",
    "    print(\"Not a race day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36bbce20-4f61-428a-af8a-17a907e1f85a",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Function to check the run status of workflow & Pipelines"
    }
   },
   "outputs": [],
   "source": [
    "def monitor_workflow_and_pipelines(run_id, pipeline_ids, workflow_name, wait_minutes):\n",
    "    \"\"\"Monitor workflow and pipeline status\"\"\"\n",
    "    start_time = time.time()\n",
    "    timeout = wait_minutes * 60\n",
    "    \n",
    "    while time.time() - start_time < timeout:\n",
    "        # Check workflow status\n",
    "        run = sdk_workspace_client.jobs.get_run(run_id=run_id)\n",
    "        workflow_state = run.state.life_cycle_state\n",
    "        \n",
    "        # Check pipeline statuses\n",
    "        pipeline_statuses = []\n",
    "        for pipeline_id in pipeline_ids:\n",
    "            try:\n",
    "                pipeline = sdk_workspace_client.pipelines.get(pipeline_id=pipeline_id)\n",
    "                pipeline_statuses.append({\n",
    "                    'pipeline_id': pipeline_id,\n",
    "                    'state': pipeline.state,\n",
    "                    'health': pipeline.health\n",
    "                })\n",
    "            except Exception as e:\n",
    "                pipeline_statuses.append({\n",
    "                    'pipeline_id': pipeline_id,\n",
    "                    'state': 'ERROR',\n",
    "                    'error': str(e)\n",
    "                })\n",
    "        \n",
    "        # Create status report\n",
    "        status = {\n",
    "            'workflow_name': workflow_name,\n",
    "            'run_id': run_id,\n",
    "            'workflow_state': workflow_state,\n",
    "            'workflow_running': workflow_state in [RunLifeCycleState.PENDING, RunLifeCycleState.RUNNING],\n",
    "            'pipelines': pipeline_statuses,\n",
    "            'pipelines_running': sum(1 for p in pipeline_statuses if p['state'] == PipelineState.RUNNING),\n",
    "            'all_triggered': False\n",
    "        }\n",
    "        \n",
    "        # Check if both workflow and first dlt pipeline is triggered\n",
    "        workflow_triggered = status['workflow_running']\n",
    "        pipelines_triggered = any(p['state'] in [PipelineState.RUNNING, PipelineState.IDLE] for p in pipeline_statuses)\n",
    "        \n",
    "        status['all_triggered'] = workflow_triggered and (not pipeline_ids or pipelines_triggered)\n",
    "        \n",
    "        # Return if all triggered or workflow completed\n",
    "        if status['all_triggered'] or workflow_state == RunLifeCycleState.TERMINATED:\n",
    "            return status\n",
    "        \n",
    "        time.sleep(30)  # Check every 30 seconds\n",
    "    \n",
    "    status['timeout'] = True\n",
    "    return status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "51a3b088-8cb1-44b4-ad88-3c8e5fd46e79",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Check if the Pipeline & DLT is Triggered"
    }
   },
   "outputs": [],
   "source": [
    "monitor_workflow_and_pipelines(run.run_id, pipeline_ids, wf_job_name, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2fc29f5d-5d11-43ff-918e-3484e24e21ad",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Not a Race Day - Stop the WF & DLT pipeline"
    }
   },
   "outputs": [],
   "source": [
    "if not is_race_day:\n",
    "    print(\"Not a race day, stopping the pipelines\")\n",
    "\n",
    "    # Extract all the job list, by default descending runs first\n",
    "    wagering_dashboard_wf_active_runs = sdk_workspace_client.jobs.list_runs(job_id=wf_job_id)\n",
    "    if wagering_dashboard_wf_active_runs:\n",
    "        active_runs = list(wagering_dashboard_wf_active_runs)\n",
    "    \n",
    "    # Extract the latest run_id for the above job_id\n",
    "    if active_runs[0].state.life_cycle_state == RunLifeCycleState.RUNNING:\n",
    "        active_run_id = active_runs[0].run_id\n",
    "\n",
    "        # Stop the workflow\n",
    "        sdk_workspace_client.jobs.cancel_run(run_id=active_run_id)\n",
    "        print(f\"Cancel request submitted to the workflow: {wf_job_name} with run ID: {active_run_id}\")\n",
    "        print(f\"check the run status here: --> https://{workspace_url}/jobs/{wf_job_id}/runs/{active_run_id}\")\n",
    "\n",
    "    # MV CUSTOMER SEGMENT DLT PIPELINE\n",
    "    customer_segment_pl_id = pipeline_ids[0]\n",
    "    customer_segment = sdk_workspace_client.pipelines.get(pipeline_id = customer_segment_pl_id)\n",
    "    if customer_segment.state == PipelineState.RUNNING:\n",
    "        try:\n",
    "            # Stop the pipeline\n",
    "            sdk_workspace_client.pipelines.stop(pipeline_id=customer_segment_pl_id)\n",
    "            print(f\"Stop request submitted to the pipeline: {customer_segment.name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error stopping {customer_segment.name} pipeline: {e}\")    \n",
    "\n",
    "        # Wait for the pipeline to stop\n",
    "        while customer_segment.state == PipelineState.RUNNING:\n",
    "            print(f\"waiting for {customer_segment.name} pipeline to stop...\")\n",
    "            time.sleep(10)\n",
    "            customer_segment = sdk_workspace_client.pipelines.get(pipeline_id = customer_segment_pl_id)\n",
    "            print(f\"Pipeline state: {customer_segment.state}\")\n",
    "\n",
    "    # WAGERING DASHBOARD DLT PIPELINE\n",
    "    wagering_dashboard_pl_id = pipeline_ids[1]\n",
    "    wagering_dashboard = sdk_workspace_client.pipelines.get(pipeline_id = wagering_dashboard_pl_id)\n",
    "    if wagering_dashboard.state == PipelineState.RUNNING:\n",
    "        try:\n",
    "            # Stop the pipeline\n",
    "            sdk_workspace_client.pipelines.stop(pipeline_id=wagering_dashboard_pl_id)\n",
    "            print(f\"Stop request submitted to the pipeline: {wagering_dashboard.name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error stopping {wagering_dashboard.name} pipeline: {e}\")    \n",
    "\n",
    "        # Wait for the pipeline to stop\n",
    "        while wagering_dashboard.state == PipelineState.RUNNING:\n",
    "            print(f\"waiting for {wagering_dashboard.name} pipeline to stop...\")\n",
    "            time.sleep(10)\n",
    "            wagering_dashboard = sdk_workspace_client.pipelines.get(pipeline_id = wagering_dashboard_pl_id)\n",
    "            print(f\"Pipeline state: {wagering_dashboard.state}\")\n",
    "    print(\"Pipelines are not running\")\n",
    "    for i in pipeline_ids:\n",
    "        print(sdk_workspace_client.pipelines.get(pipeline_id = i).state)\n",
    "else:\n",
    "    print(\"It's a race day, pipelines won't stop until midnight...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "add9ec75-f7ea-4772-97f1-1bfc77165785",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "dlt starter wf notebook",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
